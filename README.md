## Comparison

This README file details the answers to the 'Comparison' section of Assignment 01, which is essentially on how my own implementation compares with the one generated by an LLM. Below are the questions and answers respectively.

---

### Which tool(s) did you use?

I used GPT-5.2 Codex model within GitHub Copilot Chat inside VSCode to generate the implementation codes, based on the requirements from the PDF instructions

---

### If you used an LLM, what was your prompt to the LLM?

First prompt: 
`Hey chat, could you read the pdf instruction and take notes on the implementation tasks on family tree generation, with reference to the csv data files in this folder, help me generate the necessary classes and functions so that all the required features are implemented?`

Second prompt: 
`There are errors in the tree generated, the people by decade counts shows 2 in 1940 and 1 in 2130, both bounds are not allowed`

Third prompt: 
`Its not simply about clamping the years of the partners' year_born, the rule is that the family starts with the first 2 original people both born in 1950 as a married couple`

---

### What differences are there between your implementation and the LLM?

**1. Code organisation**
My implementation separates concerns into distinct modules (`person.py`, `person_factory.py`, `family_tree.py`, `main.py`, `utils.py`). GPT packs everything — `Person`, `PersonFactory`, `FamilyTree`, helper functions, and the CLI — into a single 300-line file.

**2. `Person` class design**
I use a traditional class with private attributes (e.g. `_year_born`) and explicit getters/setters (e.g. `get_year_born()`, `set_partner()`). GPT uses a Python `@dataclass` with all fields public and no accessor methods.

**3. Original people's names**
My implementation explicitly sets the two original people to "Desmond Jones" and "Molly Smith" after creation, which matches the assignment specification. GPT randomly generates the founders' names just like any other person — no specific names are enforced.

**4. Queue processing / child-generation bug**
My `generate_tree()` puts only `original_person1` in the queue. Partners are created but never queued, so children are produced exactly once per couple. GPT's `generate()` puts **both** founders in the queue. When `founder_two` is later dequeued, `_create_children(founder_two)` runs a second time and creates an entirely new set of children, resulting in duplicate/extra children for the founding couple.

**5. Missing-decade fallback**
GPT defines a `closest_key()` helper that finds the nearest available decade when a birth year falls outside the CSV data range. My code assumes the exact decade always exists; it would raise a `KeyError` for out-of-range years.

**6. CSV parsing**
GPT uses `csv.DictReader`, which handles quoted fields and is tolerant of extra whitespace. My code uses manual `line.split(',')`, which would break on any value that contains a comma or surrounding spaces.

**7. Last-name inheritance for children**
My implementation randomly picks one of the two founder last names for every descendant. GPT assigns the processing parent's own last name directly to each child, which means last names propagate down a single lineage rather than being drawn from the founding pair.

**8. Single-child birth year**
My code places a single child at a random year within the fertile window (`randint(start, end)`). GPT places the single child exactly at the midpoint of the window.

**9. Configurable behaviour flags**
GPT exposes `--no-gender-probabilities` and `--no-single-parent-reduction` as CLI flags, making the grad-student features opt-out. My implementation always applies them (hardcoded behaviour).

---

### What changes would you make to your implementation based on suggestions from the LLM?

**1. Last-name inheritance for children**
I feel it would make more sense to stick to the direct-descendant parent's last name down the lineage instead of keeping the random selection of the 2 original last-names for every generation down the tree

**2. Switch to `csv.DictReader`**
`csv.DictReader` is the preferred way to read CSV files in Python. It makes the column mapping explicit by name instead of positional index, handles quoting and whitespace automatically, and makes the parsing code shorter and easier to maintain across all six `read_*` methods.

---

### What changes would you refuse to make?

**1. Replacing getters/setters with a `@dataclass`**
Using `@dataclass` with fully public fields removes the encapsulation boundary. Any caller could mutate `person.year_born` directly, bypassing any future validation logic. The explicit getter/setter design is the right choice for a domain object that other classes depend on.

**2. Adding both founders to the generation queue**
GPT's design of queueing both founders causes `_create_children` to run twice for the founding couple, producing an extra independent batch of children for `founder_two`. This is a correctness bug. My approach of queueing only one member of a couple is the correct pattern and must be kept.

**3. Add a `closest_key` / nearest-decade fallback**
Currently in my code, a birth year slightly outside the CSV range (e.g., 2121) would crash with a `KeyError`. However, although a fallback to the nearest available decade is a small change, my code by design will not allow a key > 2120 to be ever created, moreover, I feel that such 'graceful' fallback actually masks the more serious issue of creating out-of-bound keys in the first place.